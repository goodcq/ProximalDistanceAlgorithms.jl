---
title: Benchmarks 3, Convex Clustering
---

```{julia; echo=false; results="hidden"}
include("plotutils.jl")
include("tableutils.jl")
#
#   build summary function
#
problem = "cvxcluster"
params = [:dataset, :features, :samples, :classes]
grouping = [:dataset, :features, :samples, :classes, :algorithm]
transformations = (
        :cpu_time => mean,
        :cpu_time => std,
    )
summarize = function(x, transformations; kwargs...)
    df = summarize_experiments(problem, x, params;
        transformations=transformations, kwargs...)
    return df
end
```

```{julia; echo=false}
CLEAN = false

if CLEAN
    #
    # missing columns
    #
    PROBLEM = Dict(
        :zoo         => (dataset="zoo", features=16, samples=101, classes=7),
        :iris        => (dataset="iris", features=4, samples=150, classes=3),
        :gaussian300 => (dataset="gaussian300", features=2, samples=300, classes=3),
        :spiral500   => (dataset="spiral500", features=2, samples=500, classes=2),
    )
    DIREXAMPLE = joinpath("aw-area51", "cvxcluster")
    for example in ["zoo", "iris", "gaussian300", "spiral500"]
        println("Processing example $(example)")
        #
        # benchmark files; need to add dataset column
        #
        println("   Checking benchmark files...")
        for file in glob("*$(example)*.dat", joinpath(DIREXAMPLE, "benchmarks"))
            println("   - $(file) matched.")
            df = CSV.read(file)
            cols = [:dataset]
            vals = [example]
            tmp = add_missing_columns(df, cols, vals)
            CSV.write(file, tmp)
        end
        #
        # validation files; need to rename classes => clusters and add dataset, features, samples, and classes columns
        #
        println("   Checking validation files...")
        for file in glob("*$(example)*validation.out", joinpath(DIREXAMPLE, "benchmarks"))
            println("   - $(file) matched.")
            #
            # read and rename
            #
            df = CSV.read(file)
            if !hasproperty(df, :clusters)
                tmp = rename(df, :classes => :clusters)
            end
            #
            # extract problem data and add to DataFrame
            #
            key = Symbol(example)
            probdata = PROBLEM[key]
            cols = keys(probdata)
            vals = values(probdata)
            tmp = add_missing_columns(tmp, cols, vals)
            CSV.write(file, tmp)
        end
        #
        # history files; need to add dataset, features, samples, and classes columns
        #
        println("   Checking history files...")
        for file in glob("*$(example)*.dat", joinpath(DIREXAMPLE, "figures"))
            println("   - $(file) matched.")
            #
            # read, extract problem data, and add to DataFrame
            #
            df = CSV.read(file)
            key = Symbol(example)
            probdata = PROBLEM[key]
            cols = keys(probdata)
            vals = values(probdata)
            tmp = add_missing_columns(df, cols, vals)
            CSV.write(file, tmp)
        end
        println()
    end
end
```

### MM (w/ CG)
```{julia; echo=false}
colnames = [
    "dataset",
    "covariates",
    "samples",
    "classes",
    "time (mean)",
    "time (std)",
]
df = summarize("MM*.dat", transformations, regex=r"[^_]*_")
rename!(df, colnames)
sort!(df, [:samples, :covariates])
latexify(df, fmt = FancyNumberFormatter(4))
```

### Steepest Descent

```{julia; echo=false}
colnames = [
    "dataset",
    "covariates",
    "samples",
    "classes",
    "time (mean)",
    "time (std)",
]
df = summarize("SD*.dat", transformations, regex=r"[^_]*_")
rename!(df, colnames)
sort!(df, [:samples, :covariates])
latexify(df, fmt = FancyNumberFormatter(4))
```

### Table 3

Results generated by benchmarks, using the search heuristic described in Algorithm 1 within the text.
The search heuristic generates multiple candidate clusterings, and the optimal clustering is chosen based on the maximum adjusted Rand index (ARI) value (relative to the ground truth; larger is better).

- `dataset`: name of dataset used in clustering problem
- `d`: number of features/covariates
- `n`: number of samples
- `k`: number of classes (ground truth)
- `*time`: average time (in seconds) for running search heuristic, based on 10 replicates
- `*dist`: distance to constraint set *for best candidate* ($\times 10^{3}$)
- `ARI*`: adjusted Rand index *for best candidate*
- `ncand*`: number of candidate clusterings generated by the search heuristic

```{julia; echo=false}
#
#   selected algorithms
#
experiments = ("MM_CG", "SD",)
#
#   benchmark data
#
transformations = (
    :cpu_time => mean,
)
benchmark = DataFrame[]
for experiment in experiments
    push!(benchmark, summarize(experiment*"*.dat", transformations,
        directory="benchmarks", regex=r"[^_]*_"))
end
#
#   convergence history + validation metrics
#
history = DataFrame[]
for experiment in experiments
    raw1 = glob_benchmark_data(problem, experiment*"*_validation.out", params, regex=r"[^_]*_")
    raw2 = glob_benchmark_data(problem, experiment*"*.dat", params, regex=r"[^_]*_", directory="figures")
    gdf1 = groupby(raw1, params)
    gdf2 = groupby(raw2, params)
    optimal = DataFrame[]

    for (sub1, sub2) in zip(gdf1, gdf2)
        idx = argmax(sub1.ARI)
        tmp1 = DataFrame(sub1[idx,:])
        tmp2 = DataFrame(sub2[idx,:])

        # add column to indicate number of candidate clusterings
        n = nrow(sub1)
        tmp1.candidates = [n]
        push!(optimal, join(tmp1, tmp2, on=[params; :algorithm]))
    end

    push!(history, vcat(optimal...))
end

# sort table by samples, then features
for i in eachindex(benchmark)
    sort!(benchmark[i], [:samples, :features])
    sort!(history[i], [:samples, :features])
end

# set scaling for columns
tscale = 1e0
lscale = 1e0
dscale = 1e3
iscale = 1e0

# assemble table
maindf = DataFrame(
           dataset = benchmark[1].dataset,
           d       = benchmark[1].features,
           n       = benchmark[1].samples,
           k       = benchmark[1].classes,
           timeMM  = benchmark[1][!, 5] * tscale,
           timeSD  = benchmark[2][!, 5] * tscale,
           distMM  = history[1][!,14] * dscale,
           distSD  = history[2][!,14] * dscale,
           ARIMM   = history[1][!, 8],
           ARISD   = history[2][!, 8],
           ncandMM = history[1][!,11],
           ncandSD = history[2][!,11],
       )

# pass to Latexify for formatting and pretty printing
latexify(maindf, fmt = FancyNumberFormatter(4))
```
