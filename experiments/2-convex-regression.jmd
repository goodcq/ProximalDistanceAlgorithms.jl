---
title: Example 2, Convex Regression
weave_options:
    fig_ext: .svg
---

```{julia}
using ProximalDistanceAlgorithms
using LinearAlgebra, Random, Plots, DataFrames
include("plotutils.jl")
```

### Introduction

```{julia}
@doc cvxreg_fit
```

### Example

```{julia}
φ(x) = dot(x, x)
d = 1       # number of covariates
n = 50      # number of samples
σ = 0.1     # std dev in noise
Random.seed!(512)
response, truth, covariates = cvxreg_example(φ, d, n, σ)
fig = plot(xlabel = "x", ylabel = "phi(x)")
plot!(fig, vec(covariates), truth, label = "ground truth")
scatter!(fig, vec(covariates), response, label = "observed", markersize = 4)
```

#### Setup

```{julia}
function solve(response, covariates, algorithm, maxiters, penalty; mu = 1.0)
    # use Nesterov acceleration unless we're running ADMM
    accel = algorithm isa ADMM ? Val(:none) : Val(:nesterov)

    if algorithm isa SteepestDescent
        println("Steepest Descent + Nesterov")

        # track loss, penalized objective, gradient, etc.
        history = initialize_history(maxiters+1)

        # warm-up
        println(" | warm-up:")
        print(" | ")
        @time cvxreg_fit(algorithm, response, covariates,
            maxiters = 100,
            penalty = penalty,
            accel = accel,
            history = history)

        # real timing
        println(" | result:")
        print(" | ")
        history = initialize_history(maxiters+1)
        solution, _ = @time cvxreg_fit(algorithm, response, covariates,
            maxiters = maxiters,
            penalty = penalty,
            accel = accel,
            history = history)
    else
        algstr = algorithm isa MM ? "MM + Nesterov" : "ADMM"
        println(algstr)

        # track loss, penalized objective, gradient, etc.
        h1 = initialize_history(maxiters+1)
        h2 = initialize_history(maxiters+1)
        history = (lsqr = h1, cg = h2)

        # store solutions
        sol = []

        for (ls, h) in zip((Val(:LSQR), Val(:CG)), (h1, h2))
            lsstr = ls isa Val{:LSQR} ? "LSQR"  : "CG"
            println(" |")
            println(" | linear solver: $(lsstr)")

            # warm-up
            println(" | warm-up:")
            print(" | ")
            tmp = initialize_history(maxiters+1)
            @time cvxreg_fit(algorithm, response, covariates,
                maxiters = 100,
                penalty = penalty,
                accel = accel,
                history = tmp,
                ls = ls,
                mu = mu)

            # real timing
            println(" | result:")
            print(" | ")
            s, _ = @time cvxreg_fit(algorithm, response, covariates,
                maxiters = maxiters,
                penalty = penalty,
                accel = accel,
                history = h,
                ls = ls,
                mu = mu)

            push!(sol, s)
        end

        solution = (lsqr=sol[1], cg=sol[2])
    end

    return solution, history
end
```

### Fusion matrix

```{julia}
D = CvxRegFM(covariates); S = instantiate_fusion_matrix(D)
size(D)
```

```{julia}
unicodeplots()
spy(S)
```

```{julia}
spy(S'S)
```

#### Annealing schedules

```{julia}
penalty(ρ, n) = min(1e3, 1.1 ^ floor(n/20))
gr(linewidth=2)

maxiters = 1000
xs = 1:maxiters
plot(xs, penalty.(1.0, xs), legend = nothing)
xlabel!("iteration")
ylabel!("rho")
```

##### MM

```{julia}
MM_sol, MM_trace = solve(response, covariates, MM(), maxiters, penalty)
plot_summary(MM_trace.lsqr)
```

```{julia}
plot_summary(MM_trace.cg)
```

### Steepest Descent

```{julia}
SD_sol, SD_trace = solve(response, covariates, SteepestDescent(), maxiters, penalty);
plot_summary(SD_trace)
```

### ADMM

```{julia}
ADMM_sol, ADMM_trace = solve(response, covariates, ADMM(), maxiters, penalty)
plot_summary(ADMM_trace.lsqr)
```

```{julia}
plot_summary(ADMM_trace.cg)
```

### MM Subspace

```{julia}
MMS3_sol, MMS3_trace = solve(response, covariates, MMSubSpace(3), maxiters, penalty);
plot_summary(MMS3_trace.lsqr)
```

```{julia}
plot_summary(MMS3_trace.cg)
```

```{julia}
MMS5_sol, MMS5_trace = solve(response, covariates, MMSubSpace(5), maxiters, penalty);
plot_summary(MMS5_trace.lsqr)
```

```{julia}
plot_summary(MMS5_trace.cg)
```

```{julia}
MMS10_sol, MMS10_trace = solve(response, covariates, MMSubSpace(10), maxiters, penalty);
plot_summary(MMS10_trace.lsqr)
```

```{julia}
plot_summary(MMS10_trace.cg)
```

### Quality of solutions

```{julia}
using Statistics
algorithm = ["MM", "SD", "ADMM", "MMS(3)", "MMS(5)", "MMS(10)"]
traces = (MM_trace, SD_trace, ADMM_trace, MMS3_trace, MMS5_trace, MMS10_trace)
df = table_summary(traces..., algname = algorithm)

df[!, :MSE] = [
    mean((MM_sol.lsqr    .- truth) .^ 2),
    mean((MM_sol.cg      .- truth) .^ 2),
    mean((SD_sol         .- truth) .^ 2),
    mean((ADMM_sol.lsqr  .- truth) .^ 2),
    mean((ADMM_sol.cg    .- truth) .^ 2),
    mean((MMS3_sol.lsqr  .- truth) .^ 2),
    mean((MMS3_sol.cg    .- truth) .^ 2),
    mean((MMS5_sol.lsqr  .- truth) .^ 2),
    mean((MMS5_sol.cg    .- truth) .^ 2),
    mean((MMS10_sol.lsqr .- truth) .^ 2),
    mean((MMS10_sol.cg   .- truth) .^ 2),
]
df
```

### Appendix

```{julia}
using Pkg; Pkg.status()
```

```{julia}
using InteractiveUtils; versioninfo()
```
