---
title: Example 2, Convex Regression
weave_options:
    fig_ext: .svg
---

```{julia}
using ProximalDistanceAlgorithms
using LinearAlgebra, Random, Plots, DataFrames
include("plotutils.jl")
```

### Introduction

```{julia}
@doc cvxreg_fit
```

### Example

```{julia}
φ(x) = dot(x, x)
d = 1       # number of covariates
n = 50      # number of samples
σ = 0.1     # std dev in noise
Random.seed!(5357)
response, truth, covariates = cvxreg_example(φ, d, n, σ)
fig = plot(xlabel = "x", ylabel = "phi(x)")
plot!(fig, vec(covariates), truth, label = "ground truth")
scatter!(fig, vec(covariates), response, label = "observed", markersize = 4)
```

#### Setup

```{julia}
function solve(response, covariates, algorithm, maxiters, penalty; mu = 1.0)
    # use Nesterov acceleration unless we're running ADMM
    accel = algorithm isa ADMM ? Val(:none) : Val(:nesterov)

    if algorithm isa SteepestDescent
        println("Steepest Descent + Nesterov")

        # track loss, penalized objective, gradient, etc.
        history = initialize_history(maxiters+1)

        # warm-up
        println(" | warm-up:")
        print(" | ")
        @time cvxreg_fit(algorithm, response, covariates,
            maxiters = 100,
            penalty = penalty,
            accel = accel,
            history = history)

        # real timing
        println(" | result:")
        print(" | ")
        history = initialize_history(maxiters+1)
        solution, _ = @time cvxreg_fit(algorithm, response, covariates,
            maxiters = maxiters,
            penalty = penalty,
            accel = accel,
            history = history)
    else
        algstr = algorithm isa MM ? "MM + Nesterov" : "ADMM"
        println(algstr)

        # track loss, penalized objective, gradient, etc.
        h1 = initialize_history(maxiters+1)
        h2 = initialize_history(maxiters+1)
        history = (lsqr = h1, cg = h2)

        # store solutions
        sol = []

        for (ls, h) in zip((Val(:LSQR), Val(:CG)), (h1, h2))
            lsstr = ls isa Val{:LSQR} ? "LSQR"  : "CG"
            println(" |")
            println(" | linear solver: $(lsstr)")

            # warm-up
            println(" | warm-up:")
            print(" | ")
            tmp = initialize_history(maxiters+1)
            @time cvxreg_fit(algorithm, response, covariates,
                maxiters = 100,
                penalty = penalty,
                accel = accel,
                history = tmp,
                ls = ls,
                mu = mu)

            # real timing
            println(" | result:")
            print(" | ")
            s, _ = @time cvxreg_fit(algorithm, response, covariates,
                maxiters = maxiters,
                penalty = penalty,
                accel = accel,
                history = h,
                ls = ls,
                mu = mu)

            push!(sol, s)
        end

        solution = (lsqr=sol[1], cg=sol[2])
    end

    return solution, history
end
```

### Fusion matrix

```{julia}
D = CvxRegFM(covariates); S = instantiate_fusion_matrix(D)
size(D)
```

```{julia}
unicodeplots()
spy(S)
```

```{julia}
spy(S'S)
```

#### Annealing schedules

```{julia}
penalty1(ρ, n) = min(1e6, 1.1 ^ floor(n/20))
penalty2(ρ, n) = min(1e6, 1.1 ^ floor(n/50))
gr(linewidth=2)

maxiters = 2000
xs = 1:maxiters
plot(xs, penalty1.(1, xs), label = "MM/SD")
plot!(xs, penalty2.(1, xs), label = "ADMM")
xlabel!("iteration")
ylabel!("rho")
```

##### MM

```{julia}
MM_sol, MM_trace = solve(response, covariates, MM(), maxiters, penalty1)
plot_summary(MM_trace.lsqr)
```

```{julia}
plot_summary(MM_trace.cg)
```

### Steepest Descent

```{julia}
SD_sol, SD_trace = solve(response, covariates, SteepestDescent(), maxiters, penalty1)
plot_summary(SD_trace)
```

### ADMM

```{julia}
ADMM_sol, ADMM_trace = solve(response, covariates, ADMM(), maxiters, penalty2, mu = 1e-1)
plot_summary(ADMM_trace.lsqr)
```

```{julia}
plot_summary(ADMM_trace.cg)
```

### Quality of solutions

```{julia}
using Statistics
df = table_summary(MM_trace, SD_trace, ADMM_trace)
df[!, :MSE] = [
    mean((MM_sol.lsqr   .- truth) .^ 2),
    mean((MM_sol.cg     .- truth) .^ 2),
    mean((SD_sol        .- truth) .^ 2),
    mean((ADMM_sol.lsqr .- truth) .^ 2),
    mean((ADMM_sol.cg   .- truth) .^ 2)
]
df
```

### Appendix

```{julia}
using Pkg; Pkg.status()
```

```{julia}
using InteractiveUtils; versioninfo()
```
